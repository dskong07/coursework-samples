{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "285a4873-ff33-4ff1-b7d2-0032254484fe",
   "metadata": {},
   "source": [
    "## <font color='red'> INSTRUCTIONS </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89957ed8-c2d1-4592-8821-88806390d1cc",
   "metadata": {},
   "source": [
    "<b> \n",
    "1. Write your code only in cells below the \"WRITE CODE BELOW\" title. Do not modify the code below the \"DO NOT MODIFY\" title. <br>\n",
    "2. The expected data types of the output answers for each question are given in the last cell through assertion statements. Your answers must match these expected output data types. Hint: Many of the answers need to be a Python dictionary. Consider methods like to_dict() to convert a Pandas Series to a dictionary. <br>\n",
    "3. The answers are then written to a JSON file named my_results_PA1.json. You can compare this with the provided expected output file \"expected_results_PA1.json\". <br>\n",
    "4. After you complete writing your code, click \"Kernel -> Restart Kernel and Run All Cells\" on the top toolbar. There should NOT be any syntax/runtime errors, otherwise points will be deducted. <br>\n",
    "5. For submitting your solution, first download your notebook by clicking \"File -> Download\". Rename the file as &ltTEAM_ID&gt.ipynb\" and upload to Canvas.</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5f7e94-c5b1-494c-8aab-832242527a4e",
   "metadata": {},
   "source": [
    "## <font color='red'> DO NOT MODIFY </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76f3c8d7-690f-428b-982d-94265b4a7f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Client: 'tcp://172.31.28.77:8786' processes=0 threads=0, memory=0 B>\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "from dask.distributed import Client\n",
    "import ctypes\n",
    "import numpy as np\n",
    "\n",
    "def trim_memory() -> int:\n",
    "    \"\"\"\n",
    "    helps to fix any memory leaks.\n",
    "    \"\"\"\n",
    "    libc = ctypes.CDLL(\"libc.so.6\")\n",
    "    return libc.malloc_trim(0)\n",
    "\n",
    "client = Client(\"127.0.0.1:8786\")\n",
    "client.run(trim_memory)\n",
    "client = client.restart()\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb6ac532-d64f-4659-9cc8-94481f48c366",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3b6eb9-e5d7-423a-a0bc-7b86e6db1ab4",
   "metadata": {},
   "source": [
    "## <font color='blue'> WRITE CODE BELOW </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf416f4d-1782-4fa5-9b2b-b44aafd55934",
   "metadata": {},
   "outputs": [],
   "source": [
    "### read in the 'user_reviews.csv' and 'products.csv' files, perform your calculations and place the answers in variables ans1 - ans7.\n",
    "\n",
    "path_reviews = 'user_reviews.csv'\n",
    "path_prod = 'products.csv'\n",
    "cols1 = ['asin', 'overall']\n",
    "cols2 = ['asin', 'price']\n",
    "\n",
    "reviews = dd.read_csv(path_reviews)\n",
    "products = dd.read_csv(path_prod, dtype = {'asin' : object})\n",
    "\n",
    "#one______________________________________________________________________________________________________\n",
    "\n",
    "one = reviews.isnull().mean()\n",
    "\n",
    "#two_______________________________________________________________________________________________________\n",
    "ddf2 = dd.read_csv(path2, usecols = cols2, dtype = {'asin': object})\n",
    "missing_values2 = ddf2.isnull().sum()\n",
    "percent_missing2 = round(((missing_values2 / ddf2.index.size) * 100).compute(), 2)\n",
    "\n",
    "#three______________________________________________________________________________________________________\n",
    "\n",
    "ddf = dd.read_csv(path_reviews, usecols = cols1)\n",
    "\n",
    "ddf2 = dd.read_csv(path_prod, usecols = cols2, dtype = {'asin': object})\n",
    "join = ddf.merge(ddf2, how=\"inner\", on=[\"asin\"])\n",
    "three = join[[\"price\", \"overall\"]].corr(method='pearson')\n",
    "\n",
    "#four______________________________________________________________________________________________________\n",
    "\n",
    "path2 = 'products.csv'\n",
    "cols2 = ['price']\n",
    "ddf2 = dd.read_csv(path2, usecols = cols2)\n",
    "four = ddf2['price'].describe()\n",
    "\n",
    "#five______________________________________________________________________________________________________\n",
    "\n",
    "path2 = 'products.csv'\n",
    "\n",
    "col = ['categories']\n",
    "\n",
    "products = dd.read_csv(path2, usecols = col)\n",
    "\n",
    "def helper(x):\n",
    "    myList = eval(x)\n",
    "    #x.split(\"',\", 1)[0].split(\"[\", 1)[0].split(\"']\", 1)[0][3:]\n",
    "    #lambda x : eval(x[0][0])\n",
    "    return myList[0][0]\n",
    "\n",
    "\n",
    "def helper2(categories):\n",
    "    if pd.isna(categories):\n",
    "        return \"\"\n",
    "    return categories.split(\"',\", 1)[0].split(\"\\\",\", 1)[0].split(\"']\", 1)[0][3:]\n",
    "\n",
    "five = products[\"categories\"].dropna().apply(helper, meta = ('categories', 'str')).value_counts()\n",
    "\n",
    "#six______________________________________________________________________________________________________\n",
    "\n",
    "def dangling6(x, y):\n",
    "    tocheck = set(y)\n",
    "    for i in x.asin:\n",
    "        if i not in tocheck:\n",
    "            #print(i)\n",
    "            return 1\n",
    "    return 0\n",
    "r_asin = dd.read_csv('user_reviews.csv', usecols = ['asin'])\n",
    "p_asin = dd.read_csv('products.csv', usecols = ['asin'], dtype = {'asin':object})\n",
    "prodid = p_asin.asin\n",
    "\n",
    "#seven______________________________________________________________________________________________________\n",
    "\n",
    "products = dd.read_csv(\"products.csv\", usecols = ['asin', 'related'], dtype = {\"asin\" : object, \"related\" : object})#.compute()\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def dangling_reference_exist2(products):\n",
    "\n",
    "    product_ids = set(products.asin.compute())\n",
    "\n",
    "    for _, row in products.iterrows():\n",
    "        if pd.isna(row['related']):\n",
    "            continue\n",
    "        for k, v in eval(row['related']).items():\n",
    "            \n",
    "            for value in v:\n",
    "                if value not in product_ids:\n",
    "                    return 1\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "\n",
    "one, two, three, four, five, prodid = dask.compute(one, two, three, four, five, prodid )\n",
    "\n",
    "# substitute 'None' with the outputs from your calculations. \n",
    "# The expected output types can be seen in the assertion statements below\n",
    "ans1 = (one.round(4)*100).to_dict()\n",
    "ans2 = percent_missing2\n",
    "ans3 = float(round(three.iloc[0, 1], 2))\n",
    "ans4 = four[['mean', 'std', 'min', 'max', '50%']].to_dict()\n",
    "ans5 = five.to_dict()\n",
    "del ans5['']\n",
    "ans6 = dangling6(r_asin, prodid)\n",
    "ans7 = dangling_reference_exist2(products)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d92954-28b3-4ad0-b7de-d8b8f4816c80",
   "metadata": {},
   "source": [
    "## <font color='red'> DO NOT MODIFY </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c438177d-8c4d-4871-bbc6-bea2f0a004b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0adca53b-b276-4297-8434-6c0e94810d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execution time = 144.19235253334045s\n"
     ]
    }
   ],
   "source": [
    "print(f\"execution time = {end-start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "935be195-dcc9-4e97-911a-bae25e2a70f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MODIFY\n",
    "assert type(ans1) == dict, f\"answer to question 1 must be a dictionary like {{'reviewerID':0.2, ..}}, got type = {type(ans1)}\"\n",
    "assert type(ans2) == dict, f\"answer to question 2 must be a dictionary like {{'asin':0.2, ..}}, got type = {type(ans2)}\"\n",
    "assert type(ans3) == float, f\"answer to question 3 must be a float like 0.8, got type = {type(ans3)}\"\n",
    "assert type(ans4) == dict, f\"answer to question 4 must be a dictionary like {{'mean':0.4,'max':0.6,'median':0.6...}}, got type = {type(ans4)}\"\n",
    "assert type(ans5) == dict, f\"answer to question 5 must be a dictionary, got type = {type(ans5)}\"         \n",
    "assert ans6 == 0 or ans6==1, f\"answer to question 6 must be 0 or 1, got value = {ans6}\" \n",
    "assert ans7 == 0 or ans7==1, f\"answer to question 7 must be 0 or 1, got value = {ans7}\" \n",
    "\n",
    "ans_dict = {\n",
    "    \"q1\": ans1,\n",
    "    \"q2\": ans2,\n",
    "    \"q3\": ans3,\n",
    "    \"q4\": ans4,\n",
    "    \"q5\": ans5,\n",
    "    \"q6\": ans6,\n",
    "    \"q7\": ans7,\n",
    "    \"runtime\": end-start\n",
    "}\n",
    "with open('my_results_PA1.json', 'w') as outfile: json.dump(ans_dict, outfile)         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
